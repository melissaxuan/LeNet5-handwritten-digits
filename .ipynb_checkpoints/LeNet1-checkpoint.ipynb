{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdTzfiZkkSgt"
   },
   "source": [
    "### LeNet5 1998 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siRujQdNkKIX"
   },
   "source": [
    "#### 1. Calculating the mean and variance of the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eqUYcp-jQZC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST data loader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor (scales to [0, 1])\n",
    "    transforms.Lambda(lambda x: x * 1.275 - 0.1)  # Normalize as per the given formula\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Check the mean and variance of the transformed data\n",
    "data_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "all_data = []\n",
    "\n",
    "for images, _ in data_loader:\n",
    "    all_data.append(images.view(images.size(0), -1))\n",
    "\n",
    "all_data = torch.cat(all_data, dim=0)\n",
    "mean = all_data.mean()\n",
    "variance = all_data.var()\n",
    "\n",
    "# Mean and Variance to use for MNIST data:\n",
    "print(f'Mean: {mean.item()}')\n",
    "print(f'Variance: {variance.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvQvd-eRkbLk"
   },
   "source": [
    "#### 2. Building the LeNet5 1998 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8topbYkh4UV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "class LeNet5_S2Layer(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(LeNet5_S2Layer, self).__init__()\n",
    "        self.coefficient = nn.Parameter(torch.ones(num_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled = nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        pooled = pooled * self.coefficient.view(1, -1, 1, 1)\n",
    "        pooled = pooled + self.bias.view(1, -1, 1, 1)\n",
    "        return torch.sigmoid(pooled)\n",
    "\n",
    "class ScaledTanh(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 1.7159 * torch.tanh(x * 2 / 3)\n",
    "\n",
    "class SquashingFunction(nn.Module):\n",
    "    def __init__(self, A=1.7159, S=2/3):\n",
    "        super(SquashingFunction, self).__init__()\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.S * x\n",
    "        x = torch.clamp(x, min=-0.999, max=0.999)  # avoid NaNs from atanh\n",
    "        return self.A * torch.atanh(x)\n",
    "\n",
    "class C3PartialConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, connection_table):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.connection_table = connection_table\n",
    "\n",
    "        # All connections are initialized, then masked\n",
    "        self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        self.mask = torch.zeros_like(self.weight)\n",
    "\n",
    "        # Build the binary mask\n",
    "        for out_c, in_list in enumerate(connection_table):\n",
    "            for in_c in in_list:\n",
    "                self.mask[out_c, in_c, :, :] = 1.0\n",
    "\n",
    "        # Initialize only the allowed weights\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        nn.init.uniform_(self.weight, -2.4 / fan_in, 2.4 / fan_in)\n",
    "        self.bias.data.fill_(2.4 / fan_in)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply mask before convolution to zero-out unwanted connections\n",
    "        masked_weight = self.weight * self.mask.to(self.weight.device)\n",
    "        return F.conv2d(x, masked_weight, self.bias, stride=1)\n",
    "\n",
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through all class labels (0-9)\n",
    "        for label in range(10):\n",
    "            class_dir = os.path.join(image_dir, str(label))  # folder names are 0, 1, 2, ..., 9\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(label)  # Assign the class label (folder name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale ('L' mode)\n",
    "\n",
    "        # Apply transformation (resize, tensor conversion, normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "class EuclideanRBFOutput(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_dim=84):\n",
    "        super(EuclideanRBFOutput, self).__init__()\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, input_dim))  # trainable prototypes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, input_dim)\n",
    "        centers = self.centers.unsqueeze(0)  # (1, num_classes, input_dim)\n",
    "        distances = torch.sum((x - centers) ** 2, dim=2)  # (batch_size, num_classes)\n",
    "        return -distances  # negative distances for CrossEntropyLoss\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # C1 and S2\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            ScaledTanh(),\n",
    "            LeNet5_S2Layer(6)\n",
    "        )\n",
    "\n",
    "        # C3 and S4\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            ScaledTanh(),\n",
    "            LeNet5_S2Layer(16)\n",
    "        )\n",
    "\n",
    "        # C5\n",
    "        self.layer3 = C3PartialConv(in_channels=16, out_channels=120, kernel_size=5, connection_table=[random.sample(range(16), 5) for _ in range(120)])\n",
    "\n",
    "        # F6\n",
    "        self.fc = nn.Linear(120, 84)\n",
    "        self.squashing = SquashingFunction(A=1.0, S=1.0)\n",
    "\n",
    "        # RBF Output layer\n",
    "        self.rbf_output = EuclideanRBFOutput(num_classes=num_classes, input_dim=84)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.squashing(out)\n",
    "        out = self.rbf_output(out)\n",
    "        return out\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.squashing(x)\n",
    "        return x\n",
    "\n",
    "def extract_features_from_digit_dataset(model, digit_loader, device):\n",
    "    model.eval()\n",
    "    features_by_class = defaultdict(list)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in digit_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Extract features from penultimate layer\n",
    "            feats = model.extract_features(images)\n",
    "            \n",
    "            for f, label in zip(feats, labels):\n",
    "                features_by_class[label.item()].append(f.cpu().numpy())\n",
    "    \n",
    "    return features_by_class\n",
    "\n",
    "def compute_rbf_centers(features_by_class, num_classes, input_dim):\n",
    "    centers = np.zeros((num_classes, input_dim), dtype=np.float32)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        class_feats = np.stack(features_by_class[cls])\n",
    "        centers[cls] = np.mean(class_feats, axis=0)\n",
    "    \n",
    "    return torch.tensor(centers, dtype=torch.float32)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()  # Output: (1, 32, 32)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your images are in 'digit_images/' and labels are stored in a separate file\n",
    "image_dir = './digits updated/'\n",
    "labels = [0, 1, 2, ...]  # The list of labels corresponding to each image\n",
    "\n",
    "digit_dataset = DigitDataset(image_dir=image_dir, labels=labels, transform=transform)\n",
    "digit_loader = DataLoader(digit_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Assuming you've loaded DIGIT dataset and computed features\n",
    "digit_loader = DataLoader(DigitDataset(...), batch_size=32)\n",
    "features_by_class = extract_features_from_digit_dataset(model, digit_loader, device)\n",
    "\n",
    "# Compute RBF centers using the features from DIGIT\n",
    "rbf_centers = compute_rbf_centers(features_by_class, num_classes=10, input_dim=84)\n",
    "\n",
    "# Set the computed centers into the model\n",
    "model.rbf_output.centers.data = rbf_centers.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLzPIMBfkg39"
   },
   "source": [
    "#### 3. Loading in the MNIST data and splitting into training and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0Z2e6nIjhsl"
   },
   "outputs": [],
   "source": [
    "# Training and testing the model on MNIST data:\n",
    "\n",
    "# Define relevant variables\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = True,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
    "    download = False\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(\"data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fl0LmTonknwb"
   },
   "source": [
    "#### 4. Training the model on MNIST data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jOwihTljq_r"
   },
   "outputs": [],
   "source": [
    "# Training the model on MNIST data:\n",
    "\n",
    "model = LeNet5(num_classes).to(device)\n",
    "features_by_class = extract_features_from_digit_dataset(model, digit_loader, device)\n",
    "\n",
    "# Initialize RBF centers from class means\n",
    "rbf_centers = compute_rbf_centers(features_by_class, num_classes=10, input_dim=84)\n",
    "model.rbf_output.centers.data = rbf_centers.to(device)\n",
    "\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tracking accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIyH489Ckr3y"
   },
   "source": [
    "#### 5. Testing the model on MNIST data subset produces ~97% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5GG_V1ah6Rq",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Testing the model on MNIST data:\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
