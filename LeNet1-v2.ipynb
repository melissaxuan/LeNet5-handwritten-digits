{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036718c1",
   "metadata": {},
   "source": [
    "### 1. LeNet5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "931a1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ScaledTanh(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 1.7159 * torch.tanh(x * 2 / 3)\n",
    "    \n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.tanh = ScaledTanh()\n",
    "\n",
    "        # C1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        \n",
    "        # S2\n",
    "        self.weight2 = nn.Parameter(torch.ones(1, 6, 1, 1))\n",
    "        self.bias2 = nn.Parameter(torch.zeros(1, 6, 1, 1))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight2)\n",
    "        nn.init.uniform_(self.weight2, -2.4 / fan_in, 2.4 / fan_in)\n",
    "        self.bias2.data.fill_(2.4 / fan_in)\n",
    "\n",
    "        # C3\n",
    "        self.weight3 = nn.Parameter(torch.Tensor(16, 6, 5, 5))\n",
    "        self.bias3 = nn.Parameter(torch.Tensor(1, 16, 1, 1))  # Shape [16] instead of [1, 16, 1, 1]\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight3)\n",
    "        nn.init.uniform_(self.weight3, -2.4 / fan_in, 2.4 / fan_in)\n",
    "        self.bias3.data.fill_(2.4 / fan_in)\n",
    "\n",
    "        # S4\n",
    "        self.weight4 = nn.Parameter(torch.ones(1, 16, 1, 1))\n",
    "        self.bias4 = nn.Parameter(torch.zeros(1, 16, 1, 1))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight4)\n",
    "        nn.init.uniform_(self.weight4, -2.4 / fan_in, 2.4 / fan_in)\n",
    "        self.bias4.data.fill_(2.4 / fan_in)\n",
    "\n",
    "        # C5\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "\n",
    "        # F6\n",
    "        self.fc6 = nn.Linear(120, 84)\n",
    "\n",
    "        # Output Layer\n",
    "        self.prototypes = self.compute_rbf_prototypes()\n",
    "\n",
    "    def connection_table(self):\n",
    "        return [\n",
    "            [0, 1, 2],\n",
    "            [1, 2, 3],\n",
    "            [2, 3, 4],\n",
    "            [3, 4, 5],\n",
    "            [0, 4, 5],\n",
    "            [0, 1, 5],\n",
    "            [0, 1, 2, 3],\n",
    "            [1, 2, 3, 4],\n",
    "            [2, 3, 4, 5],\n",
    "            [0, 3, 4, 5],\n",
    "            [0, 1, 4, 5],\n",
    "            [0, 1, 2, 5],\n",
    "            [0, 1, 3, 4],\n",
    "            [1, 2, 4, 5],\n",
    "            [1, 2, 3, 5],\n",
    "            [0, 1, 2, 3, 4, 5]\n",
    "        ]\n",
    "\n",
    "    def compute_rbf_prototypes(self):\n",
    "        prototypes = []\n",
    "\n",
    "        image_folder = './digits updated/'\n",
    "        images = []\n",
    "        labels = []\n",
    "        bitmap_size = (7,12)\n",
    "        num_classes = 10\n",
    "\n",
    "        for label in range(num_classes):\n",
    "            class_folder = os.path.join(image_folder, str(label))\n",
    "            for img_name in os.listdir(class_folder):\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "                labels.append(label)\n",
    "                image = cv2.imread(img_path, 0)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, bitmap_size)\n",
    "                    images.append(image)\n",
    "            if images:\n",
    "                mean_image = np.mean(images, axis=0)\n",
    "                # mean_image = cv2.threshold(mean_image, 127, 1, cv2.THRESH_BINARY)[1].astype(np.int16) * -1 + 1 # black = 0, white = 1 for loss later\n",
    "                prototypes.append(mean_image.flatten())\n",
    "\n",
    "        prototypes_arr = np.array(prototypes)\n",
    "        return torch.tensor(prototypes_arr, dtype=torch.float32)\n",
    "\n",
    "    def compute_rbf_distance(self, x):\n",
    "        x_expanded = x.unsqueeze(1).expand((x.size(0), self.prototypes.size(0), self.prototypes.size(1)))  \n",
    "        params_expanded = self.prototypes.unsqueeze(0).expand((x.size(0), self.prototypes.size(0), self.prototypes.size(1)))         \n",
    "        output = (x_expanded - params_expanded).pow(2).sum(-1)\n",
    "        return output    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # C1\n",
    "        x = self.conv1(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        # S2\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2) * self.weight2.view(1, -1, 1, 1) + self.bias2.view(1, -1, 1, 1)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        # C3\n",
    "        batch_size = x.size(0)\n",
    "        output = torch.zeros(batch_size, 16, x.size(2) - 5 + 1, x.size(3) - 5 + 1).to(x.device)\n",
    "        for i in range(16):  # For each output channel\n",
    "            connected_channels = self.connection_table()[i]\n",
    "            for j, input_channel in enumerate(connected_channels): # input channels 0-5\n",
    "                input_slice = x[:, input_channel, :, :].unsqueeze(1)  # Select the input channel and add batch dimension\n",
    "                \n",
    "                # Create the weight tensor for the convolution (shape: [1, 1, 5, 5])\n",
    "                weight = self.weight3[i, j, :, :].unsqueeze(0).unsqueeze(0)\n",
    "                \n",
    "                # Perform convolution (output will have shape [batch_size, 1, height, width])\n",
    "                conv_output = F.conv2d(input_slice, weight)\n",
    "                \n",
    "                # print(conv_output.shape)\n",
    "                \n",
    "                # Accumulate results in the correct output channel\n",
    "                output[:, i:i+1, :, :] += conv_output\n",
    "                # print(output.shape)\n",
    "\n",
    "        bias = self.bias3.view(16)  # shape: [16]\n",
    "        for i in range(16):\n",
    "            output[:, i:i+1, :, :] += bias[i]\n",
    "        # print(output.shape)\n",
    "        x = output\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        # S4\n",
    "        x = F.avg_pool2d(x, kernel_size=2, stride=2) * self.weight4.view(1, -1, 1, 1) + self.bias4.view(1, -1, 1, 1)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        # C5\n",
    "        x = self.conv5(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        # F6\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "        # Output Layer\n",
    "        x = self.compute_rbf_distance(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cac26b",
   "metadata": {},
   "source": [
    "### 2. Load Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "820d833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "train_image_folder = './data/train/'\n",
    "test_image_folder = './data/test/'\n",
    "train_label_file = './data/train_label.txt'\n",
    "test_label_file = './data/test_label.txt'\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize images to 32x32\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float)\n",
    "])\n",
    "\n",
    "with open(train_label_file, 'r') as f:\n",
    "    label_lines = f.readlines()\n",
    "\n",
    "    for idx, img_name in enumerate(os.listdir(train_image_folder)):\n",
    "        img_path = os.path.join(train_image_folder, img_name)\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        if img is not None:\n",
    "            image = Image.fromarray(img)\n",
    "            image = transform(image)\n",
    "            train_images.append(image)\n",
    "            label = int(label_lines[idx].strip())\n",
    "            train_labels.append(label)\n",
    "\n",
    "with open(test_label_file, 'r') as f:\n",
    "    label_lines = f.readlines()\n",
    "\n",
    "    for idx, img_name in enumerate(os.listdir(test_image_folder)):\n",
    "        img_path = os.path.join(test_image_folder, img_name)\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        if img is not None:\n",
    "            image = Image.fromarray(img)\n",
    "            image = transform(image)\n",
    "            test_images.append(image)\n",
    "            label = int(label_lines[idx].strip())\n",
    "            test_labels.append(label)\n",
    "\n",
    "train_images = torch.stack(train_images)\n",
    "test_images = torch.stack(test_images)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_images, train_labels), batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(test_images, test_labels), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca28891",
   "metadata": {},
   "source": [
    "### 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83586ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(outputs, labels):\n",
    "    predicted_class = torch.argmax(outputs, dim=1)  # Get the predicted class (32,)\n",
    "    # correct_predictions = (predicted_class == labels)  # Tensor of booleans (32,)\n",
    "    # print(\"predicted class:\", predicted_class, \"labels:\", labels)\n",
    "    loss = outputs[labels==predicted_class] # .pow(2).sum() # correct classes\n",
    "    # print(\"loss1:\", loss)\n",
    "    loss += torch.log(np.exp(-0.1) + torch.exp(-outputs[labels!=predicted_class].sum())) # incorrect classes\n",
    "    # print(\"loss2:\", loss)\n",
    "    loss /= 10 # normalize by number of classes\n",
    "    # print(\"loss3:\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet5(num_classes=num_classes).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "print(f'Total steps: {total_step}')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = customLoss(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tracking accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i+1) % 200 == 0:\n",
    "            accuracy = 100 * correct / total\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Training Accuracy: {:.2f}%'.format(epoch+1, num_epochs, i+1, total_step, loss.item(), accuracy))\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeNet5-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
