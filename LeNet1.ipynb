{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdTzfiZkkSgt"
   },
   "source": [
    "### LeNet5 1998 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siRujQdNkKIX"
   },
   "source": [
    "#### 1. Calculating the mean and variance of the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /common/home/mx92/Desktop/CS461/myenv/lib/python3.10/site-packages (20.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4eqUYcp-jQZC"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splits, df_train, df_test\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a custom dataset class to handle this data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomMNISTDataset\u001b[39;00m(Dataset):\n",
      "File \u001b[0;32m~/Desktop/CS461/LeNet5-handwritten-digits/data.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      4\u001b[0m splits \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist/train-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist/test-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m----> 5\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf://datasets/ylecun/mnist/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf://datasets/ylecun/mnist/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m splits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parquet.py:651\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[1;32m    500\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    1    4    9\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m     impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m    654\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    655\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_nullable_dtypes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    656\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    657\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parquet.py:67\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     65\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from data import splits, df_train, df_test\n",
    "\n",
    "# Create a custom dataset class to handle this data\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image data (assuming it's stored in columns 'image')\n",
    "        image = self.dataframe.iloc[idx]['image']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        \n",
    "        # Convert the image (which is assumed to be a 28x28 numpy array) to a PIL image\n",
    "        image = Image.fromarray(image.astype(np.uint8), mode='L')\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define the transformation (normalize according to the given formula)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor (scales to [0, 1])\n",
    "    transforms.Lambda(lambda x: x * 1.275 - 0.1)  # Normalize as per the given formula\n",
    "])\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = CustomMNISTDataset(dataframe=df_train, transform=transform)\n",
    "test_dataset = CustomMNISTDataset(dataframe=df_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Check the mean and variance of the transformed data\n",
    "all_data = []\n",
    "\n",
    "for images, _ in train_loader:\n",
    "    all_data.append(images.view(images.size(0), -1))\n",
    "\n",
    "all_data = torch.cat(all_data, dim=0)\n",
    "mean = all_data.mean()\n",
    "variance = all_data.var()\n",
    "\n",
    "# Mean and Variance to use for MNIST data:\n",
    "print(f'Mean: {mean.item()}')\n",
    "print(f'Variance: {variance.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvQvd-eRkbLk"
   },
   "source": [
    "#### 2. Building the LeNet5 1998 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8topbYkh4UV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "class LeNet5_S2Layer(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(LeNet5_S2Layer, self).__init__()\n",
    "        self.coefficient = nn.Parameter(torch.ones(num_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        pooled = nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "        pooled = pooled * self.coefficient.view(1, -1, 1, 1)\n",
    "        pooled = pooled + self.bias.view(1, -1, 1, 1)\n",
    "        return torch.sigmoid(pooled)\n",
    "\n",
    "class ScaledTanh(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 1.7159 * torch.tanh(x * 2 / 3)\n",
    "\n",
    "class SquashingFunction(nn.Module):\n",
    "    def __init__(self, A=1.7159, S=2/3):\n",
    "        super(SquashingFunction, self).__init__()\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.S * x\n",
    "        x = torch.clamp(x, min=-0.999, max=0.999)  # avoid NaNs from atanh\n",
    "        return self.A * torch.atanh(x)\n",
    "\n",
    "class C3PartialConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, connection_table):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.connection_table = connection_table\n",
    "\n",
    "        # All connections are initialized, then masked\n",
    "        self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        self.mask = torch.zeros_like(self.weight)\n",
    "\n",
    "        # Build the binary mask\n",
    "        for out_c, in_list in enumerate(connection_table):\n",
    "            for in_c in in_list:\n",
    "                self.mask[out_c, in_c, :, :] = 1.0\n",
    "\n",
    "        # Initialize only the allowed weights\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        nn.init.uniform_(self.weight, -2.4 / fan_in, 2.4 / fan_in)\n",
    "        self.bias.data.fill_(2.4 / fan_in)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply mask before convolution to zero-out unwanted connections\n",
    "        masked_weight = self.weight * self.mask.to(self.weight.device)\n",
    "        return F.conv2d(x, masked_weight, self.bias, stride=1)\n",
    "\n",
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Loop through all class labels (0-9)\n",
    "        for label in range(10):\n",
    "            class_dir = os.path.join(image_dir, str(label))\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(label)  # Assign the class label (folder name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('L')  # Convert to grayscale ('L' mode)\n",
    "\n",
    "        # Apply transformation (resize, tensor conversion, normalization)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "class EuclideanRBFOutput(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_dim=84):\n",
    "        super(EuclideanRBFOutput, self).__init__()\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, input_dim))  # trainable prototypes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, input_dim)\n",
    "        centers = self.centers.unsqueeze(0)  # (1, num_classes, input_dim)\n",
    "        distances = torch.sum((x - centers) ** 2, dim=2)  # (batch_size, num_classes)\n",
    "        return -distances  # negative distances for CrossEntropyLoss\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        # C1 and S2\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            ScaledTanh(),\n",
    "            LeNet5_S2Layer(6)\n",
    "        )\n",
    "\n",
    "        # C3 and S4\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            ScaledTanh(),\n",
    "            LeNet5_S2Layer(16)\n",
    "        )\n",
    "\n",
    "        # C5\n",
    "        self.layer3 = C3PartialConv(in_channels=16, out_channels=120, kernel_size=5, connection_table=[random.sample(range(16), 5) for _ in range(120)])\n",
    "\n",
    "        # F6\n",
    "        self.fc = nn.Linear(120, 84)\n",
    "        self.squashing = SquashingFunction(A=1.0, S=1.0)\n",
    "\n",
    "        # RBF Output layer\n",
    "        self.rbf_output = EuclideanRBFOutput(num_classes=num_classes, input_dim=84)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.squashing(out)\n",
    "        out = self.rbf_output(out)\n",
    "        return out\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.squashing(x)\n",
    "        return x\n",
    "\n",
    "def extract_features_from_digit_dataset(model, digit_loader, device):\n",
    "    model.eval()\n",
    "    features_by_class = defaultdict(list)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in digit_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Extract features from penultimate layer\n",
    "            feats = model.extract_features(images)\n",
    "            \n",
    "            for f, label in zip(feats, labels):\n",
    "                features_by_class[label.item()].append(f.cpu().numpy())\n",
    "    \n",
    "    return features_by_class\n",
    "\n",
    "def compute_rbf_centers(features_by_class, num_classes, input_dim):\n",
    "    centers = np.zeros((num_classes, input_dim), dtype=np.float32)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        class_feats = np.stack(features_by_class[cls])\n",
    "        centers[cls] = np.mean(class_feats, axis=0)\n",
    "    \n",
    "    return torch.tensor(centers, dtype=torch.float32)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()  # Output: (1, 32, 32)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLzPIMBfkg39"
   },
   "source": [
    "#### 3. Loading in the MNIST data and splitting into training and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0Z2e6nIjhsl"
   },
   "outputs": [],
   "source": [
    "# Training and testing the model on MNIST data:\n",
    "\n",
    "# Define relevant variables\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = True,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
    "    download = False\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(\"data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5(num_classes).to(device)\n",
    "\n",
    "# Assuming your images are in 'digit_images/' and labels are stored in a separate file\n",
    "image_dir = './digits updated/'\n",
    "\n",
    "digit_dataset = DigitDataset(image_dir=image_dir, transform=transform)\n",
    "digit_loader = DataLoader(digit_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Assuming you've loaded DIGIT dataset and computed features\n",
    "digit_loader = DataLoader(digit_dataset, batch_size=32)\n",
    "features_by_class = extract_features_from_digit_dataset(model, digit_loader, device)\n",
    "\n",
    "# Compute RBF centers using the features from DIGIT\n",
    "rbf_centers = compute_rbf_centers(features_by_class, num_classes=10, input_dim=84)\n",
    "\n",
    "# Set the computed centers into the model\n",
    "model.rbf_output.centers.data = rbf_centers.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fl0LmTonknwb"
   },
   "source": [
    "#### 4. Training the model on MNIST data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jOwihTljq_r"
   },
   "outputs": [],
   "source": [
    "# Training the model on MNIST data:\n",
    "\n",
    "features_by_class = extract_features_from_digit_dataset(model, digit_loader, device)\n",
    "\n",
    "# Initialize RBF centers from class means\n",
    "rbf_centers = compute_rbf_centers(features_by_class, num_classes=10, input_dim=84)\n",
    "model.rbf_output.centers.data = rbf_centers.to(device)\n",
    "\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Tracking accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIyH489Ckr3y"
   },
   "source": [
    "#### 5. Testing the model on MNIST data subset produces ~97% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5GG_V1ah6Rq"
   },
   "outputs": [],
   "source": [
    "# Testing the model on MNIST data:\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
