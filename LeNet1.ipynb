{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### LeNet5 1998 Implementation"
      ],
      "metadata": {
        "id": "BdTzfiZkkSgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Calculating the mean and variance of the MNIST data."
      ],
      "metadata": {
        "id": "siRujQdNkKIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# MNIST data loader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor (scales to [0, 1])\n",
        "    transforms.Lambda(lambda x: x * 1.275 - 0.1)  # Normalize as per the given formula\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Check the mean and variance of the transformed data\n",
        "data_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "all_data = []\n",
        "\n",
        "for images, _ in data_loader:\n",
        "    all_data.append(images.view(images.size(0), -1))\n",
        "\n",
        "all_data = torch.cat(all_data, dim=0)\n",
        "mean = all_data.mean()\n",
        "variance = all_data.var()\n",
        "\n",
        "# Mean and Variance to use for MNIST data:\n",
        "print(f'Mean: {mean.item()}')\n",
        "print(f'Variance: {variance.item()}')"
      ],
      "metadata": {
        "id": "4eqUYcp-jQZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Building the LeNet5 1998 model."
      ],
      "metadata": {
        "id": "tvQvd-eRkbLk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8topbYkh4UV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "class LeNet5_S2Layer(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(LeNet5_S2Layer, self).__init__()\n",
        "        self.coefficient = nn.Parameter(torch.ones(num_channels))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        pooled = nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n",
        "        pooled = pooled * self.coefficient.view(1, -1, 1, 1)\n",
        "        pooled = pooled + self.bias.view(1, -1, 1, 1)\n",
        "        return torch.sigmoid(pooled)\n",
        "\n",
        "class ScaledTanh(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 1.7159 * torch.tanh(x * 2 / 3)\n",
        "\n",
        "class SquashingFunction(nn.Module):\n",
        "    def __init__(self, A=1.7159, S=2/3):\n",
        "        super(SquashingFunction, self).__init__()\n",
        "        self.A = A\n",
        "        self.S = S\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.S * x\n",
        "        x = torch.clamp(x, min=-0.999, max=0.999)  # avoid NaNs from atanh\n",
        "        return self.A * torch.atanh(x)\n",
        "\n",
        "class C3PartialConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, connection_table):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.connection_table = connection_table\n",
        "\n",
        "        # All connections are initialized, then masked\n",
        "        self.weight = nn.Parameter(torch.zeros(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
        "        self.mask = torch.zeros_like(self.weight)\n",
        "\n",
        "        # Build the binary mask\n",
        "        for out_c, in_list in enumerate(connection_table):\n",
        "            for in_c in in_list:\n",
        "                self.mask[out_c, in_c, :, :] = 1.0\n",
        "\n",
        "        # Initialize only the allowed weights\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "        nn.init.uniform_(self.weight, -2.4 / fan_in, 2.4 / fan_in)\n",
        "        self.bias.data.fill_(2.4 / fan_in)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply mask before convolution to zero-out unwanted connections\n",
        "        masked_weight = self.weight * self.mask.to(self.weight.device)\n",
        "        return F.conv2d(x, masked_weight, self.bias, stride=1)\n",
        "\n",
        "class EuclideanRBFOutput(nn.Module):\n",
        "    def __init__(self, num_classes=10, input_dim=84):\n",
        "        super(EuclideanRBFOutput, self).__init__()\n",
        "        self.centers = nn.Parameter(torch.randn(num_classes, input_dim))  # trainable prototypes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # (batch_size, 1, input_dim)\n",
        "        centers = self.centers.unsqueeze(0)  # (1, num_classes, input_dim)\n",
        "        distances = torch.sum((x - centers) ** 2, dim=2)  # (batch_size, num_classes)\n",
        "        return -distances  # negative distances for CrossEntropyLoss\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        # C1 and S2\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
        "            ScaledTanh(),\n",
        "            LeNet5_S2Layer(6)\n",
        "        )\n",
        "\n",
        "        # C3 and S4\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
        "            ScaledTanh(),\n",
        "            LeNet5_S2Layer(16)\n",
        "        )\n",
        "\n",
        "        # C5\n",
        "        self.layer3 = C3PartialConv(in_channels=16, out_channels=120, kernel_size=5, connection_table=[random.sample(range(16), 5) for _ in range(120)])\n",
        "\n",
        "        # F6\n",
        "        self.fc = nn.Linear(120, 84)\n",
        "        self.squashing = SquashingFunction(A=1.0, S=1.0)\n",
        "\n",
        "        # RBF Output layer\n",
        "        self.rbf_output = EuclideanRBFOutput(num_classes=num_classes, input_dim=84)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.squashing(out)\n",
        "        out = self.rbf_output(out)\n",
        "        return out\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.squashing(x)\n",
        "        return x\n",
        "\n",
        "def compute_rbf_centers(model, dataloader, device, num_classes, input_dim):\n",
        "    model.eval()\n",
        "    features_by_class = defaultdict(list)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            feats = model.extract_features(images)\n",
        "\n",
        "            for f, label in zip(feats, labels):\n",
        "                features_by_class[label.item()].append(f.cpu().numpy())\n",
        "\n",
        "    centers = np.zeros((num_classes, input_dim), dtype=np.float32)\n",
        "    for cls in range(num_classes):\n",
        "        class_feats = np.stack(features_by_class[cls])\n",
        "        centers[cls] = np.mean(class_feats, axis=0)\n",
        "\n",
        "    return torch.tensor(centers, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Loading in the MNIST data and splitting into training and testing data sets."
      ],
      "metadata": {
        "id": "wLzPIMBfkg39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing the model on MNIST data:\n",
        "\n",
        "# Define relevant variables\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Loading the dataset and preprocessing\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root = './data',\n",
        "    train = True,\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize((32,32)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
        "    download = True\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root = './data',\n",
        "    train = False,\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize((32,32)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean = (0.06659211218357086,), std = (0.15432125329971313,))]),\n",
        "    download = False\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "print(\"data loaded\")"
      ],
      "metadata": {
        "id": "J0Z2e6nIjhsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Training the model on MNIST data subset."
      ],
      "metadata": {
        "id": "fl0LmTonknwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model on MNIST data:\n",
        "\n",
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "# Initialize RBF centers from class means\n",
        "rbf_centers = compute_rbf_centers(model, train_loader, device, num_classes, input_dim=84)\n",
        "model.rbf_output.centers.data = rbf_centers.to(device)\n",
        "\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels)\n",
        "\n",
        "        #Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 400 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "6jOwihTljq_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Testing the model on MNIST data subset produces ~97% accuracy."
      ],
      "metadata": {
        "id": "LIyH489Ckr3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model on MNIST data:\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f} %')"
      ],
      "metadata": {
        "id": "x5GG_V1ah6Rq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
